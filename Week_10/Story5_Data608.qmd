---
title: "Story5_Data608"
author: "Mubashira Qari"
format: revealjs
editor: visual
date: 2025-3-24"
---

### Defining Business Question

This week we will learn to visualize models, and the next week we will learn about dimensionality reduction techniques. A good dataset to practice these tools on is the Ames housing price dataset, which is a sort of "model organism" for machine learning practice. The emphasis of this assignment (described in the pdf) is on building a model or models of the factors determining housing prices and using visualizations to explain their meaning and implications.

```{r, warning = FALSE, message = FALSE, echo=FALSE, include=FALSE}
# echo=FALSE, include=FALSE

# Load required libraries

library(tidyverse)
library(caret)
library(ggplot2)
library(corrplot)
library(GGally)
library(randomForest)
library(gridExtra)
library(pscl)
library(pROC)
library(MASS)
library(boot)
library(Metrics)
# Loading Dataset

housing_df <- read_csv("https://raw.githubusercontent.com/uzmabb182/Data_608/refs/heads/main/Week_10/train.csv")


head(housing_df)

```

## Exploratory Data Analysis:

```{r, warning = FALSE, message = FALSE, echo=FALSE, include=FALSE}

#glimpse(housing_df)

#skim(housing_df)
colnames(housing_df)
```

## Histogram: 

-   Visualizing the distribution of housing sale prices to spot skewness or outliers.

```{r}
# 1. Histogram of Sale Prices
ggplot(housing_df, aes(x = SalePrice)) +
  geom_histogram(fill = "steelblue", bins = 50, color = "black") +
  theme_minimal() +
  labs(title = "Sale Price Distribution")
```
## Correlation Analysis: 

-   Finding top numerical features most correlated with SalePrice and plots them in a heatmap for insight.

```{r}
# top correlated variables with SalePrice

# Compute correlations
numeric_data <- housing_df %>% select_if(is.numeric)
cor_matrix <- cor(numeric_data, use = "complete.obs")

# Find top 15 features most correlated with SalePrice
saleprice_corr <- abs(cor_matrix[, "SalePrice"])
top_vars <- names(sort(saleprice_corr, decreasing = TRUE))[1:15]

# Plot only top correlated features
library(corrplot)
corrplot::corrplot(cor_matrix[top_vars, top_vars],
                   method = "color",       # colored tiles
                   type = "upper",         # show only upper triangle
                   tl.col = "black",       # label color
                   tl.cex = 0.8,           # label size
                   number.cex = 0.7)       # correlation number size



```
## Feature Engineering: 

-   Createing new variables: 
-   log-transformed price, total bathrooms, total porch area, and house age to enhance modeling.

```{r}
# 3. Feature Engineering
housing_df <- housing_df %>%
  mutate(
    log_SalePrice = log(SalePrice),
    TotalBath = FullBath + 0.5 * HalfBath + BsmtFullBath + 0.5 * BsmtHalfBath,
    TotalPorch = OpenPorchSF + EnclosedPorch + `3SsnPorch` + ScreenPorch,
    Age = YrSold - YearBuilt
  )

```

## Visual EDA: 

-   Showing relationships (e.g., living area vs. sale price) 
-   And correlations between important features using scatter and pair plots.

```{r}
# 4. Visual Exploratory Data Analysis
top_features <- c("GrLivArea", "OverallQual", "GarageCars", "TotalBsmtSF", "YearBuilt")

# Scatter plot: GrLivArea vs SalePrice
ggplot(housing_df, aes(x = GrLivArea, y = SalePrice)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Living Area vs Sale Price")

# Pairwise plot of top features
ggpairs(housing_df, columns = which(names(housing_df) %in% top_features))



```

## Train/Test Split: 

-   Spliting the data into training (80%) and testing (20%) for unbiased model evaluation.

```{r}
# 5. Train/Test Split
set.seed(123)
split <- createDataPartition(housing_df$SalePrice, p = 0.8, list = FALSE)
train_df <- housing_df[split, ]
test_df  <- housing_df[-split, ]

```

## Linear Model: 

-   Training a basic regression model with key features.

```{r}
# 6. Linear Regression Model
model_lm <- lm(SalePrice ~ GrLivArea + OverallQual + GarageCars + TotalBsmtSF + YearBuilt, data = train_df)
summary(model_lm)

```
## Visualizing Results:

-   Predicted vs Actual Sale Prices (Train & Test Sets)
-   Means close your model's predictions are to reality

```{r}
# Predictions
train_df$Predicted <- predict(model_lm, newdata = train_df)
test_df$Predicted <- predict(model_lm, newdata = test_df)

# Visualization (Train)
ggplot(train_df, aes(x = Predicted, y = SalePrice)) +
  geom_point(alpha = 0.4, color = "dodgerblue") +
  geom_abline(slope = 1, intercept = 0, color = "darkred", linetype = "dashed") +
  labs(title = "Train Set: Predicted vs Actual Sale Price",
       x = "Predicted Price", y = "Actual Price") +
  theme_minimal()

```
## Interpretation:

-   Most points cluster tightly along the diagonal line suggest model is accurately predicting many house prices.
-   As the predicted price increases (especially > $350k), the points start to spread out more vertically, also called heteroscedasticity.
-   This means your model becomes less reliable for more expensive homes 
-   A few houses are way above or below the red line meaning large errors for a small number of homes.
-   These could be homes with unusual characteristics (e.g., poor condition, luxury materials, unique locations)
-   Current predictors don’t explain those price differences

## Visualization (Test)

```{r}
# Visualization (Test)
ggplot(test_df, aes(x = Predicted, y = SalePrice)) +
  geom_point(alpha = 0.4, color = "forestgreen") +
  geom_abline(slope = 1, intercept = 0, color = "darkred", linetype = "dashed") +
  labs(title = "Test Set: Predicted vs Actual Sale Price",
       x = "Predicted Price", y = "Actual Price") +
  theme_minimal()

```
## Interpretation:

-   Model performs fairly well on average-priced homes and generalizes decently for typical properties in Ames.
-   However, it's less reliable for expensive or atypical homes, likely due to:
-   Missing features (e.g., neighborhood, condition, amenities)
-   Linear model limitations (not capturing complex interactions or non-linear effects)
-   This reduced accuracy on the test set especially at higher prices
-   Suggests that your model is underfitting for complex cases.

## Residuals Distribution

-   Whether your errors are centered and symmetric

```{r}
# Residuals
train_df$Residuals <- resid(model_lm)

# Histogram
ggplot(train_df, aes(x = Residuals)) +
  geom_histogram(fill = "orange", color = "black", binwidth = 10000) +
  labs(title = "Distribution of Residuals (Train Set)", x = "Residuals", y = "Count") +
  theme_minimal()

```
## Interpretation:

-   The model meets a key assumption of linear regression: 
-   Residuals are approximately normally distributed.
-   However, the slight skew and long tails suggest:
-   A few homes are underpredicted by large margins (positive residuals).
-   There may be outliers or missing predictors influencing these extreme cases.
-   Overall, this supports that the model is well-calibrated for typical homes, but could be improved for edge cases.

## 3. Residuals vs Fitted Values

--  If error patterns suggest model issues (e.g. non-linearity)

```{r}
ggplot(train_df, aes(x = Predicted, y = Residuals)) +
  geom_point(alpha = 0.5, color = "purple") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs Fitted Values", x = "Predicted Price", y = "Residuals") +
  theme_minimal()

```
## Interpretation 

-   Most residuals are clustered tightly around zero.
-   Wider spread of residuals as predicted prices increase suggests heteroscedasticity.
-   Indicates increasing variance in errors — especially for expensive homes.
-   Linear model is less reliable for high-priced homes.

## 4. Feature Importance via Coefficients

-   Which features drive price most significantly

```{r}
# Extract Coefficients
coef_df <- as.data.frame(summary(model_lm)$coefficients[-1, ])  # Drop intercept
coef_df$Variable <- rownames(coef_df)

# Plot
ggplot(coef_df, aes(x = reorder(Variable, Estimate), y = Estimate)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Feature Importance (Linear Coefficients)",
       x = "", y = "Impact on SalePrice") +
  theme_minimal()

```
## Interpretation:

-   Build quality and garage space are the strongest linear predictors of home value in Ames and these are the top priorities for buyers.
-   Surprisingly, living area and basement size, though important intuitively, contribute less per unit in the linear model — possibly due to:
-   Their smaller coefficient scale (e.g., price per sq ft is lower)

## Model Performance on Test Set

-   Performance check on test data:
-   How well your model generalizes beyond training data

```{r}
# Test RMSE and R2

rmse_test <- rmse(test_df$SalePrice, test_df$Predicted)
r2_test <- 1 - sum((test_df$SalePrice - test_df$Predicted)^2) / 
                sum((test_df$SalePrice - mean(test_df$SalePrice))^2)

cat("Test RMSE:", round(rmse_test, 2), "\n")
cat("Test R-squared:", round(r2_test, 4), "\n")

```
## Interpretation:

-   RMSE (Root Mean Squared Error) measures the average prediction error in dollars
-   On average, model’s predictions are off by about $47,296.
-   R-squared explains how much variation in sale prices your model accounts for.
-   Model explains 73.1% of the variability in home prices on unseen test data.
-   Considering the typical home prices in Ames range around $150,000–$300,000, this is a moderate error, roughly 15–30% of a typical sale price.

## key visualizations

-   GrLivArea vs. SalePrice

```{r}
ggplot(housing_df, aes(x = GrLivArea, y = SalePrice)) +
  geom_point(alpha = 0.4, color = "steelblue") +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Above Ground Living Area vs Sale Price",
       x = "Above Ground Living Area (sq ft)",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation:

-   There’s a clear positive linear relationship: larger homes generally cost more.
-   Some potential outliers exist (very large homes at lower prices).

##  Overall Quality vs. SalePrice

```{r}
ggplot(housing_df, aes(x = factor(OverallQual), y = SalePrice)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Overall Quality vs Sale Price",
       x = "Overall Quality (1 = Poor, 10 = Excellent)",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation:

-   Sale price rises sharply with better overall quality.
-   A house rated 8 or above commands a premium price.
-   The relationship is non-linear and very categorical-sensitive.

## 3. Garage Capacity vs. SalePrice

```{r}
ggplot(housing_df, aes(x = factor(GarageCars), y = SalePrice)) +
  geom_boxplot(fill = "lightgreen") +
  labs(title = "Garage Capacity vs Sale Price",
       x = "Number of Garage Cars",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation:

-   Houses with 2+ car garages fetch significantly higher prices.
-   Garage capacity is both a space and status factor for buyers.

## 4.  Total Basement Area vs. SalePrice

```{r}
ggplot(housing_df, aes(x = TotalBsmtSF, y = SalePrice)) +
  geom_point(alpha = 0.4, color = "darkorange") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Total Basement Area vs Sale Price",
       x = "Total Basement Area (sq ft)",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation: 

-    Larger basements correlate with higher prices.
-   Relationship is positive but diminishing after 2000 sq ft.

## 5.  House Age vs. SalePrice

```{r}
ggplot(housing_df, aes(x = Age, y = SalePrice)) +
  geom_point(alpha = 0.3, color = "purple") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  labs(title = "House Age vs Sale Price",
       x = "House Age (Years)",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation: 

-   Newer homes (lower age) are valued higher.
-   There’s a non-linear drop-off: value decreases sharply for older homes up to \~30 years, then levels off.

## 6.  Total Bathrooms vs. SalePrice

```{r}
ggplot(housing_df, aes(x = TotalBath, y = SalePrice)) +
  geom_jitter(width = 0.2, alpha = 0.4, color = "brown") +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Total Bathrooms vs Sale Price",
       x = "Total Bathrooms (Full + 0.5 × Half)",
       y = "Sale Price") +
  theme_minimal()

```
## Interpretation: 

-   More bathrooms = higher sale price, but effect plateaus after \~3.5.
-   Suggests marginal benefit decreases for higher counts.
